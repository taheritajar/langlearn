# langlearn
language-learning-with-virtual-avatars

# Integration of Large Language Models and Virtual Avatars for Interactive Secondary Language Learning

Overview: In this project, we combine large language models with virtual agents to facilitate secondary
language learning in-situ using Augmented Reality (AR). The system allows a user with a wearable display
to interact with a virtual agent in his or her own language, converse with the agent about real objects in the
userâ€™s environment, and get level-appropriate responses from the agent to facilitate contextual learning.
To date, secondary language learning has mostly been conducted in the classroom using textbooks.
However, the most effective language programs are generally those that are immersive or happen in-context,
i.e. in-situ. Our objective is to develop a system that moves away from textbook-based education and
towards mobile, immersive learning via AI-powered Augmented Reality.
To do so, we will use a unique combination of speech-to-text, large language models (LLMs), computer
vision for object detection, and voice synthesis. These systems will be integrated into an interactive virtual
avatar that can respond to a learner in real time, recognize objects in the real world, and speak naturally in a
destination language. Most importantly, our goal is to develop a system that will check for understanding, a
skill that current LLMs are not proficient in.
